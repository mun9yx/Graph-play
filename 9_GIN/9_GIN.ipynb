{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c7f930c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset : PROTEINS(1113)\n",
      "Number of graphs : 1113\n",
      "Number of nodes : 31\n",
      "Number of features : 3\n",
      "Number of classes : 2\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root='.',name='PROTEINS').shuffle()\n",
    "\n",
    "print(f'Dataset : {dataset}')\n",
    "print(f'Number of graphs : {len(dataset)}')\n",
    "print(f'Number of nodes : {dataset[0].x.shape[0]}')\n",
    "print(f'Number of features : {dataset.num_features}')\n",
    "print(f'Number of classes : {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76592581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 144], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 52], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 56], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 30], x=[8, 3], y=[1])\n",
      "Data(edge_index=[2, 74], x=[17, 3], y=[1])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5): #확인\n",
    "    print(dataset[i])\n",
    "# y=[1] : 노드 분류가 아니라 그래프 분류. (노드 분류라면 x의 갯수와 라벨의 갯수가 동일해야 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2365ad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set : 890 graphs\n",
      "Val Set : 111 graphs\n",
      "Test Set : 112 graphs\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[:int(len(dataset)*0.8)]\n",
    "val_dataset = dataset[int(len(dataset)*0.8):int(len(dataset)*0.9)]\n",
    "test_dataset = dataset[int(len(dataset)*0.9):]\n",
    "\n",
    "print(f'Training Set : {len(train_dataset)} graphs')\n",
    "print(f'Val Set : {len(val_dataset)} graphs')\n",
    "print(f'Test Set : {len(test_dataset)} graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846f1d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader\n",
      "Batch 0 : DataBatch(edge_index=[2, 7294], x=[1973, 3], y=[64], batch=[1973], ptr=[65])\n",
      "Batch 1 : DataBatch(edge_index=[2, 9678], x=[2664, 3], y=[64], batch=[2664], ptr=[65])\n",
      "Batch 2 : DataBatch(edge_index=[2, 9174], x=[2397, 3], y=[64], batch=[2397], ptr=[65])\n",
      "Batch 3 : DataBatch(edge_index=[2, 8778], x=[2372, 3], y=[64], batch=[2372], ptr=[65])\n",
      "Batch 4 : DataBatch(edge_index=[2, 9684], x=[2650, 3], y=[64], batch=[2650], ptr=[65])\n",
      "Batch 5 : DataBatch(edge_index=[2, 10856], x=[2960, 3], y=[64], batch=[2960], ptr=[65])\n",
      "Batch 6 : DataBatch(edge_index=[2, 8166], x=[2132, 3], y=[64], batch=[2132], ptr=[65])\n",
      "Batch 7 : DataBatch(edge_index=[2, 9232], x=[2480, 3], y=[64], batch=[2480], ptr=[65])\n",
      "Batch 8 : DataBatch(edge_index=[2, 7600], x=[1990, 3], y=[64], batch=[1990], ptr=[65])\n",
      "Batch 9 : DataBatch(edge_index=[2, 10478], x=[2745, 3], y=[64], batch=[2745], ptr=[65])\n",
      "Batch 10 : DataBatch(edge_index=[2, 10654], x=[2863, 3], y=[64], batch=[2863], ptr=[65])\n",
      "Batch 11 : DataBatch(edge_index=[2, 10304], x=[2753, 3], y=[64], batch=[2753], ptr=[65])\n",
      "Batch 12 : DataBatch(edge_index=[2, 11126], x=[3137, 3], y=[64], batch=[3137], ptr=[65])\n",
      "Batch 13 : DataBatch(edge_index=[2, 7540], x=[1957, 3], y=[58], batch=[1957], ptr=[59])\n",
      "Val Loader\n",
      "Batch 0 : DataBatch(edge_index=[2, 8514], x=[2382, 3], y=[64], batch=[2382], ptr=[65])\n",
      "Batch 1 : DataBatch(edge_index=[2, 8360], x=[2122, 3], y=[47], batch=[2122], ptr=[48])\n",
      "Test Loader\n",
      "Batch 0 : DataBatch(edge_index=[2, 7494], x=[1986, 3], y=[64], batch=[1986], ptr=[65])\n",
      "Batch 1 : DataBatch(edge_index=[2, 7156], x=[1908, 3], y=[48], batch=[1908], ptr=[49])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=64,shuffle=True)\n",
    "\n",
    "print('Train Loader')\n",
    "for i,batch in enumerate(train_loader):\n",
    "    print(f'Batch {i} : {batch}')\n",
    "\n",
    "print('Val Loader')\n",
    "for i,batch in enumerate(val_loader):\n",
    "    print(f'Batch {i} : {batch}')\n",
    "\n",
    "print('Test Loader')\n",
    "for i,batch in enumerate(test_loader):\n",
    "    print(f'Batch {i} : {batch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5a91d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0) #토치의 난수생성 시드 고정\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "from torch_geometric.nn import GINConv\n",
    "from torch_geometric.nn import global_add_pool\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self,dim_h):\n",
    "        super(GIN,self).__init__()\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(dataset.num_node_features,dim_h),\n",
    "                              BatchNorm1d(dim_h),\n",
    "                              ReLU(),\n",
    "                              Linear(dim_h,dim_h),\n",
    "                              ReLU()))\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim_h,dim_h),\n",
    "                              BatchNorm1d(dim_h),\n",
    "                              ReLU(),\n",
    "                              Linear(dim_h,dim_h),\n",
    "                              ReLU()))\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim_h,dim_h),\n",
    "                              BatchNorm1d(dim_h),\n",
    "                              ReLU(),\n",
    "                              Linear(dim_h,dim_h),\n",
    "                              ReLU()))\n",
    "        self.lin1 = Linear(dim_h*3,dim_h*3)\n",
    "        self.lin2 = Linear(dim_h*3,dataset.num_classes)\n",
    "\n",
    "    def forward(self,x,edge_index,batch):\n",
    "        # 노드 임베딩\n",
    "        h1 = self.conv1(x,edge_index) # 1홉의 정보를 반영한 모든 노드 임베딩\n",
    "        h2 = self.conv2(h1,edge_index) # 2홉\n",
    "        h3 = self.conv3(h2,edge_index) # 3홉\n",
    "\n",
    "        h1 = global_add_pool(h1,batch) # 배치는 그래프의 구분 정보를 암시\n",
    "        h2 = global_add_pool(h2,batch)\n",
    "        h3 = global_add_pool(h3,batch)\n",
    "\n",
    "        #그래프 임베딩으로 표현\n",
    "        h = torch.cat((h1,h2,h3),dim=1)\n",
    "\n",
    "        #분류 신경망\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h,p=0.5,training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a314400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y):\n",
    "    return ((y_pred==y).sum() / len(y)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25b4889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model,loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    loss,acc = 0,0\n",
    "    for data in loader:\n",
    "        out = model(data.x,data.edge_index,data.batch)\n",
    "        loss += criterion(out,data.y) / len(loader)\n",
    "        acc += accuracy(out.argmax(dim=1),data.y) / len(loader)\n",
    "    \n",
    "    return loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fefc913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "    epochs = 100\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs+1):\n",
    "        total_loss,total_acc,val_loss,val_acc = 0,0,0,0\n",
    "\n",
    "        for data in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x,data.edge_index,data.batch)\n",
    "            loss = criterion(out,data.y) #하나의 로스, 스칼라 값이 나옴. (평균)\n",
    "            total_loss += loss.item() / len(loader)\n",
    "            total_acc += accuracy(out.argmax(dim=1),data.y) / len(loader)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_loss,val_acc = test(model,val_loader)\n",
    "        \n",
    "        if epoch%20==0:\n",
    "            print(f'Epoch : {epoch:>3} | Train_loss : {total_loss:.3f} | Train_acc : {total_acc*100:.3f} | Val_loss : {val_loss:.3f} | Val_acc : {val_acc*100:.3f}')\n",
    "\n",
    "    return model            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8de0a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (conv1): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=3, out_features=32, bias=True)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv2): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv3): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (lin1): Linear(in_features=96, out_features=96, bias=True)\n",
      "  (lin2): Linear(in_features=96, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gin = GIN(dim_h=32)\n",
    "print(gin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "112a22b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :   0 | Train_loss : 1.643 | Train_acc : 58.297 | Val_loss : 0.602 | Val_acc : 64.229\n",
      "Epoch :  20 | Train_loss : 0.505 | Train_acc : 77.394 | Val_loss : 0.588 | Val_acc : 75.798\n",
      "Epoch :  40 | Train_loss : 0.486 | Train_acc : 77.159 | Val_loss : 0.568 | Val_acc : 77.078\n",
      "Epoch :  60 | Train_loss : 0.482 | Train_acc : 76.736 | Val_loss : 0.510 | Val_acc : 73.454\n",
      "Epoch :  80 | Train_loss : 0.463 | Train_acc : 78.702 | Val_loss : 0.528 | Val_acc : 74.734\n",
      "Epoch : 100 | Train_loss : 0.474 | Train_acc : 76.970 | Val_loss : 0.554 | Val_acc : 74.734\n"
     ]
    }
   ],
   "source": [
    "gin_model = train(gin,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43272e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
