{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd64d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T # PyG의 그래프 전처리를 담당\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb05f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([ # 여러 전처리 함수들을 묶어서 한번에 적용\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05,num_test=0.1,is_undirected=True,split_labels=True,add_negative_train_samples=False)\n",
    "])\n",
    "# 링크 예측할 때는 전처리가 표준적임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca63f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='.',name='Cora',transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfe585a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[4488], pos_edge_label_index=[2, 4488]),\n",
       " Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[263], pos_edge_label_index=[2, 263], neg_edge_label=[263], neg_edge_label_index=[2, 263]),\n",
       " Data(x=[2708, 1433], edge_index=[2, 9502], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[527], pos_edge_label_index=[2, 527], neg_edge_label=[527], neg_edge_label_index=[2, 527]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfdb1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48de91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self,dim_in,dim_out):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dim_in,2*dim_out)\n",
    "        self.conv_mu = GCNConv(2*dim_out,dim_out)\n",
    "        self.conv_logstd = GCNConv(2*dim_out,dim_out)\n",
    "\n",
    "    def forward(self,x,edge_index):\n",
    "        x = self.conv1(x,edge_index).relu()\n",
    "        return self.conv_mu(x,edge_index),self.conv_logstd(x,edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5be3c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGAE(Encoder(dataset.num_features,16)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d3f423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGAE(\n",
      "  (encoder): Encoder(\n",
      "    (conv1): GCNConv(1433, 32)\n",
      "    (conv_mu): GCNConv(32, 16)\n",
      "    (conv_logstd): GCNConv(32, 16)\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09a05fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x,train_data.edge_index)\n",
    "    loss = model.recon_loss(z,train_data.pos_edge_label_index) + (1 / train_data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dfb658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x,data.edge_index)\n",
    "    return model.test(z,data.pos_edge_label_index,data.neg_edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cd4690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0 | Loss : 3.4739 | Val_AUC : 0.6651 | Val_AP : 0.6776\n",
      "Epoch : 50 | Loss : 1.3303 | Val_AUC : 0.6397 | Val_AP : 0.6627\n",
      "Epoch : 100 | Loss : 1.1553 | Val_AUC : 0.7237 | Val_AP : 0.7203\n",
      "Epoch : 150 | Loss : 1.1107 | Val_AUC : 0.7352 | Val_AP : 0.7329\n",
      "Epoch : 200 | Loss : 0.9996 | Val_AUC : 0.8336 | Val_AP : 0.8208\n",
      "Epoch : 250 | Loss : 0.9542 | Val_AUC : 0.8632 | Val_AP : 0.8590\n",
      "Epoch : 300 | Loss : 0.9525 | Val_AUC : 0.8743 | Val_AP : 0.8721\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(301):\n",
    "    loss = train()\n",
    "    val_auc, val_ap = test(val_data)\n",
    "    if epoch%50==0:\n",
    "        print(f'Epoch : {epoch:>2} | Loss : {loss:.4f} | Val_AUC : {val_auc:.4f} | Val_AP : {val_ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e47137e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_AUC : 0.8743 | Test_AP : 0.8721\n"
     ]
    }
   ],
   "source": [
    "test_auc, test_ap = test(test_data)\n",
    "print(f'Test_AUC : {val_auc:.4f} | Test_AP : {val_ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2cbe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7769, 0.6252, 0.7670,  ..., 0.5609, 0.8333, 0.7781],\n",
      "        [0.6252, 0.8309, 0.8431,  ..., 0.5446, 0.6965, 0.6479],\n",
      "        [0.7670, 0.8431, 0.9042,  ..., 0.5950, 0.8549, 0.7964],\n",
      "        ...,\n",
      "        [0.5609, 0.5446, 0.5950,  ..., 0.5456, 0.6046, 0.5855],\n",
      "        [0.8333, 0.6965, 0.8549,  ..., 0.6046, 0.9012, 0.8498],\n",
      "        [0.7781, 0.6479, 0.7964,  ..., 0.5855, 0.8498, 0.7963]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = model.encode(test_data.x,test_data.edge_index) # Z는 노드 임베딩\n",
    "Ahat = torch.sigmoid(z @ z.T)\n",
    "print(Ahat) # 노드 쌍이 연결된 강도, 확률, 가중치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eaa78e",
   "metadata": {},
   "source": [
    "SEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7849da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score # ML 평가지표\n",
    "from scipy.sparse.csgraph import shortest_path # 희소 행렬에서 최단거리 계산\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv1d,MaxPool1d,Linear,Dropout,BCEWithLogitsLoss \n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, aggr\n",
    "from torch_geometric.utils import k_hop_subgraph, to_scipy_sparse_matrix\n",
    "# k-hop : 누 노드 기준 k-hop 이웃으로 구성된 서브그래프 생성\n",
    "# to_scipy : PyG의 엣지 인덱스를 scipy의 sparse_matrix로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28490dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RandomLinkSplit(num_val=0.05,num_test=0.1,is_undirected=True,split_labels=True)\n",
    "# 이웃 기반이므로, 노드를 정규화할 필요 x\n",
    "dataset = Planetoid(root='.',name='Cora',transform=transform) \n",
    "train_data,val_data,test_data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "646f9048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[4488], pos_edge_label_index=[2, 4488], neg_edge_label=[4488], neg_edge_label_index=[2, 4488])\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "caf5c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seal_processing(dataset,edge_label_index,y):\n",
    "    data_list = []\n",
    "    for src,dst in edge_label_index.T.tolist(): # numpy & Tensor를 list로 변환\n",
    "        sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph([src,dst],2,dataset.edge_index,relabel_nodes=True)\n",
    "        # (src,dst)를 기준으로 2홉 이웃을 가져오고, 리라벨링을 한다.\n",
    "        # sub_nodes : 서브 그래프 노드 집합\n",
    "        # sub_edge_index : 서브그래프 기준 새 번호로 엣지 구성\n",
    "        # mapping : (src,dst)가 서브그래프 기준으로 어떤 인덱스로 바뀌었는지\n",
    "        # _ = edge_mask = 원래 edge_index 중 어떤 엣지가 서브그래프에 포함됐는지\n",
    "        src,dst = mapping.tolist()\n",
    "        mask1 = (sub_edge_index[0]!=src) | (sub_edge_index[1]!=dst)\n",
    "        mask2 = (sub_edge_index[0]!=dst) | (sub_edge_index[1]!=src)\n",
    "        sub_edge_index = sub_edge_index[:,mask1&mask2] # 모든 행 기준으로 열 조건을 만족하는 것만 추출\n",
    "\n",
    "        src,dst = (dst,src) if src>dst else (src,dst)\n",
    "        adj = to_scipy_sparse_matrix(sub_edge_index,num_nodes=sub_nodes.size(0)).tocsr() # 행렬 생성\n",
    "\n",
    "        idx = list(range(src)) + list(range(src+1,adj.shape[0])) #src를 제외한 인덱싱\n",
    "        adj_wo_src = adj[idx,:][:,idx] #제외한 행렬\n",
    "\n",
    "        idx = list(range(dst)) + list(range(dst+1,adj.shape[0])) #dst를 제외한 인덱싱\n",
    "        adj_wo_dst = adj[idx,:][:,idx] #제외한 행렬\n",
    "\n",
    "        d_src = shortest_path(adj_wo_dst, directed=False,unweighted=True,indices = src) # indices = 출발점\n",
    "        #dst를 제거한 행렬에서, src와의 거리\n",
    "        d_src = np.insert(d_src,dst,0,axis=0) # 행렬의 dst 위치에 0 삽입\n",
    "        d_src = torch.from_numpy(d_src)\n",
    "\n",
    "        d_dst = shortest_path(adj_wo_src, directed=True,unweighted=True,indices= dst-1) # 출발노드가 도착노드보다 앞서있으므로 -1\n",
    "        d_dst = np.insert(d_dst,src,0,axis=0)\n",
    "        d_dst = torch.from_numpy(d_dst)\n",
    "\n",
    "        # 공식에 맞게 노드레이블 계산\n",
    "        dist = d_src + d_dst\n",
    "        z = 1+ torch.min(d_src,d_dst) + dist // 2 * (dist // 2 + dist % 2 - 1)\n",
    "        z[src], z[dst], z[torch.isnan(z)] = 1.,1.,0. # 중심 노드는 1로 라벨링.\n",
    "        z = z.to(torch.long) # 정수로 표현 (int보다 크게)\n",
    "\n",
    "        node_labels = F.one_hot(z,num_classes=200).to(torch.float)\n",
    "        node_emb = dataset.x[sub_nodes]\n",
    "        node_x = torch.cat([node_emb,node_labels],dim=1)\n",
    "\n",
    "        data = Data(node_x,z=z,edge_index=sub_edge_index,y=y)\n",
    "        data_list.append(data)\n",
    "\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9b88b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_data_list = seal_processing(train_data,train_data.pos_edge_label_index,1)\n",
    "train_neg_data_list = seal_processing(train_data,train_data.neg_edge_label_index,0)\n",
    "\n",
    "val_pos_data_list = seal_processing(val_data,val_data.pos_edge_label_index,1)\n",
    "val_neg_data_list = seal_processing(val_data,val_data.neg_edge_label_index,0)\n",
    "\n",
    "test_pos_data_list = seal_processing(test_data,test_data.pos_edge_label_index,1)\n",
    "test_neg_data_list = seal_processing(test_data,test_data.neg_edge_label_index,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c916f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_pos_data_list + train_neg_data_list\n",
    "val_dataset = val_pos_data_list + val_neg_data_list\n",
    "test_dataset = test_pos_data_list + test_neg_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b85640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=32,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9398b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(self,dim_in,k=30):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(dim_in,32)\n",
    "        self.gcn2 = GCNConv(32,32)\n",
    "        self.gcn3 = GCNConv(32,32)\n",
    "        self.gcn4 = GCNConv(32,1)\n",
    "\n",
    "        self.global_pool = aggr.SortAggregation(k=k) # 중요도가 높은 노드 선택\n",
    "\n",
    "        self.conv1 = Conv1d(1,16,97,97)\n",
    "        self.conv2 = Conv1d(16,32,5,1)\n",
    "        self.maxpool = MaxPool1d(2,2)\n",
    "\n",
    "        self.linear1 = Linear(352,128)\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.linear2 = Linear(128,1)\n",
    "\n",
    "    def forward(self,x,edge_index,batch):\n",
    "        h1 = self.gcn1(x,edge_index).tanh()\n",
    "        h2 = self.gcn2(h1,edge_index).tanh()\n",
    "        h3 = self.gcn3(h2,edge_index).tanh()\n",
    "        h4 = self.gcn4(h3,edge_index).tanh()\n",
    "        h = torch.cat([h1,h2,h3,h4],dim=-1)\n",
    "\n",
    "        h = self.global_pool(h,batch)\n",
    "        h = h.view(h.size(0),1,h.size(-1)) # conv1d 형태로 맞춰주기.\n",
    "        h = self.conv1(h).relu()\n",
    "        h = self.maxpool(h)\n",
    "        h = self.conv2(h).relu()\n",
    "        h = h.view(h.size(0),-1) # 결과를 1차원으로 펼치고, 선형함수에 넣기 위함.\n",
    "        h = self.linear1(h).relu()\n",
    "        h = self.dropout(h)\n",
    "        h = self.linear2(h).sigmoid()\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "597e7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DGCNN(train_dataset[0].num_features).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "criterion = BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4eaeed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x,data.edge_index,data.batch)\n",
    "        loss = criterion(out.view(-1),data.y.to(torch.float)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=float(loss) * data.num_graphs\n",
    "    \n",
    "    return total_loss / len(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f024dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    y_pred,y_true = [],[]\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x,data.edge_index,data.batch)\n",
    "        y_pred.append(out.view(-1).cpu())\n",
    "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
    "    \n",
    "    acc = roc_auc_score(torch.cat(y_true),torch.cat(y_pred))\n",
    "    ap = average_precision_score(torch.cat(y_true),torch.cat(y_pred))\n",
    "\n",
    "    return acc,ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0b4ef0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0 | Loss : 0.7003 | val_auc : 0.8085 | val_ap : 0.7864\n",
      "Epoch :  1 | Loss : 0.6235 | val_auc : 0.8574 | val_ap : 0.8670\n",
      "Epoch :  2 | Loss : 0.5984 | val_auc : 0.8627 | val_ap : 0.8807\n",
      "Epoch :  3 | Loss : 0.5962 | val_auc : 0.8686 | val_ap : 0.8850\n",
      "Epoch :  4 | Loss : 0.5947 | val_auc : 0.8549 | val_ap : 0.8729\n",
      "Epoch :  5 | Loss : 0.5956 | val_auc : 0.8450 | val_ap : 0.8555\n",
      "Epoch :  6 | Loss : 0.5984 | val_auc : 0.8289 | val_ap : 0.8532\n",
      "Epoch :  7 | Loss : 0.6018 | val_auc : 0.8088 | val_ap : 0.8355\n",
      "Epoch :  8 | Loss : 0.5995 | val_auc : 0.8048 | val_ap : 0.8242\n",
      "Epoch :  9 | Loss : 0.5964 | val_auc : 0.8339 | val_ap : 0.8430\n",
      "Epoch : 10 | Loss : 0.5938 | val_auc : 0.8189 | val_ap : 0.8248\n",
      "Epoch : 11 | Loss : 0.5914 | val_auc : 0.8329 | val_ap : 0.8317\n",
      "Epoch : 12 | Loss : 0.5908 | val_auc : 0.8419 | val_ap : 0.8342\n",
      "Epoch : 13 | Loss : 0.5894 | val_auc : 0.8481 | val_ap : 0.8423\n",
      "Epoch : 14 | Loss : 0.5866 | val_auc : 0.8408 | val_ap : 0.8349\n",
      "Epoch : 15 | Loss : 0.5854 | val_auc : 0.8462 | val_ap : 0.8371\n",
      "Epoch : 16 | Loss : 0.5841 | val_auc : 0.8492 | val_ap : 0.8384\n",
      "Epoch : 17 | Loss : 0.5834 | val_auc : 0.8417 | val_ap : 0.8368\n",
      "Epoch : 18 | Loss : 0.5837 | val_auc : 0.8505 | val_ap : 0.8398\n",
      "Epoch : 19 | Loss : 0.5810 | val_auc : 0.8501 | val_ap : 0.8488\n",
      "Epoch : 20 | Loss : 0.5784 | val_auc : 0.8710 | val_ap : 0.8555\n",
      "Epoch : 21 | Loss : 0.5761 | val_auc : 0.8635 | val_ap : 0.8517\n",
      "Epoch : 22 | Loss : 0.5748 | val_auc : 0.8614 | val_ap : 0.8515\n",
      "Epoch : 23 | Loss : 0.5730 | val_auc : 0.8706 | val_ap : 0.8607\n",
      "Epoch : 24 | Loss : 0.5729 | val_auc : 0.8606 | val_ap : 0.8549\n",
      "Epoch : 25 | Loss : 0.5726 | val_auc : 0.8563 | val_ap : 0.8478\n",
      "Epoch : 26 | Loss : 0.5723 | val_auc : 0.8710 | val_ap : 0.8614\n",
      "Epoch : 27 | Loss : 0.5711 | val_auc : 0.8586 | val_ap : 0.8508\n",
      "Epoch : 28 | Loss : 0.5708 | val_auc : 0.8533 | val_ap : 0.8464\n",
      "Epoch : 29 | Loss : 0.5711 | val_auc : 0.8659 | val_ap : 0.8509\n",
      "Epoch : 30 | Loss : 0.5693 | val_auc : 0.8630 | val_ap : 0.8524\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(31):\n",
    "    loss = train()\n",
    "    val_auc, val_ap = test(val_loader)\n",
    "    print(f'Epoch : {epoch:>2} | Loss : {loss:.4f} | val_auc : {val_auc:.4f} | val_ap : {val_ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b42108b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_acu : 0.8381 | test_ap : 0.8281\n"
     ]
    }
   ],
   "source": [
    "test_auc, test_ap = test(test_loader)\n",
    "print(f'Test_acu : {test_auc:.4f} | test_ap : {test_ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f667604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
